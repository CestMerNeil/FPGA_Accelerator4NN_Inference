{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc31fd7-d33a-43ef-9457-9ac11db50dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 14:58:53.851926: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c20a307f-0a7a-451b-a6e8-b34dea73315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 784).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 784).astype(\"float32\") / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62290eda-8784-49dd-812c-2c0e395f0ac6",
   "metadata": {},
   "source": [
    "# Define the SNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "162c7264-9090-4670-a74a-88fcf239bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(SpikingLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\"kernel\", shape=[input_shape[-1], self.units])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        spikes = tf.cast(inputs > 0, dtype=tf.float32)\n",
    "        output = tf.matmul(spikes, self.kernel)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c42be1-b9c6-45d1-bdbf-76c387ce43f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 14:58:55.799428: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(units=32),\n",
    "    SpikingLayer(units=128),  # 第一层SNN层\n",
    "    layers.Activation('relu'),\n",
    "    #SpikingLayer(units=128),  # 第二层SNN层\n",
    "    #layers.Activation('relu'),\n",
    "    layers.Dense(units=10),  # 输出层\n",
    "    layers.Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce1d4d7-ebd9-4d57-aeb3-15ee42f1dbe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/backend.py:5534: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 816us/step - loss: 0.7974 - accuracy: 0.7323\n",
      "Test Loss: 0.7974334359169006\n",
      "Test Accuracy: 0.7322999835014343\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\", \n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    batch_size=5096, \n",
    "    epochs=300, \n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose = 0\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2871aaf1-5399-418e-98a9-51699363d46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                25120     \n",
      "                                                                 \n",
      " spiking_layer (SpikingLayer  (None, 128)              4096      \n",
      " )                                                               \n",
      "                                                                 \n",
      " activation (Activation)     (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,506\n",
      "Trainable params: 30,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c56441a0-4aa2-4727-90f9-d2775efdc75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"SNN_MNIST.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3494f7a0-ae32-4fb7-9ebc-edc71e7c2335",
   "metadata": {},
   "source": [
    "# hls4ml Config Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "806c5a81-b70e-4a4e-bef8-63ef6bd35d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"SNN_MNIST.h5\", custom_objects={'SpikingLayer': SpikingLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a42b167-3ed3-44cd-9dd4-fea625f9bb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 806us/step - loss: 0.7974 - accuracy: 0.7323\n",
      "Test Loss: 0.7974334359169006\n",
      "Test Accuracy: 0.7322999835014343\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                25120     \n",
      "                                                                 \n",
      " spiking_layer (SpikingLayer  (None, 128)              4096      \n",
      " )                                                               \n",
      "                                                                 \n",
      " activation (Activation)     (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,506\n",
      "Trainable params: 30,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee21fefa-1798-4130-9746-f4d19f46bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "\n",
    "class HSpikingLayer(hls4ml.model.layers.Layer):\n",
    "    def initialize(self):\n",
    "        inp = self.get_input_variable()\n",
    "        shape = inp.shape\n",
    "        dims = inp.dim_names\n",
    "        self.add_output_variable(shape, dims)\n",
    "\n",
    "    def build(self):\n",
    "        input_var = self.get_input_variable()\n",
    "        output_var = self.get_output_variable()\n",
    "        output_var.add_assignment(f'spikes = nnet::greater<{input_var.precision}, 0>({input_var()});')\n",
    "        output_var.add_assignment(f'{output_var()} = nnet::matmul<{input_var.precision}, {output_var.precision}, {output_var.target_name}>({output_var()}, spikes, {self.kernel()});')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12950241-e059-424d-b3e4-7da7d5b36c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_spiking_layer(keras_layer, input_names, input_shapes, data_reader):\n",
    "    layer = {}\n",
    "    layer['class_name'] = 'HSpikingLayer'\n",
    "    layer['name'] = keras_layer['config']['name']  \n",
    "    layer['units'] = keras_layer['config']['units'] \n",
    "\n",
    "    if input_names is not None:\n",
    "        layer['inputs'] = input_names\n",
    "\n",
    "    return layer, input_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ea8eac0-de2a-4d9a-a393-9f02c6d0facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_custom_layer():\n",
    "    hls4ml.converters.register_keras_layer_handler('SpikingLayer', parse_spiking_layer)\n",
    "    hls4ml.model.layers.register_layer('HSpikingLayer', HSpikingLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f54dd6b0-34f6-49cc-be75-af0d7a0520dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_custom_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e527ce2c-5aa7-45d1-80cb-10cf472a0413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: dense_input, layer type: InputLayer, input shapes: [[None, 784]], output shape: [None, 784]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 784]], output shape: [None, 32]\n",
      "Layer name: spiking_layer, layer type: HSpikingLayer, input shapes: [[None, 32]], output shape: [[None, 32]]\n",
      "Layer name: activation, layer type: Activation, input shapes: [[[None, 32]]], output shape: [[None, 32]]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[[None, 32]]], output shape: [10]\n",
      "Layer name: activation_1, layer type: Softmax, input shapes: [[10]], output shape: [10]\n",
      "-----------------------------------\n",
      "Model\n",
      "  Precision:         ap_fixed<12,6>\n",
      "  ReuseFactor:       1\n",
      "  Strategy:          Latency\n",
      "  BramFactor:        1000000000\n",
      "  TraceOutput:       False\n",
      "LayerName\n",
      "  dense_input\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "  dense\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<16,6>\n",
      "      bias:          fixed<16,6>\n",
      "  dense_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "  spiking_layer\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "  activation\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "  dense_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<16,6>\n",
      "      bias:          fixed<16,6>\n",
      "  dense_1_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "  activation_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "    Strategy:        Stable\n",
      "-----------------------------------\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: dense_input, layer type: InputLayer, input shapes: [[None, 784]], output shape: [None, 784]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 784]], output shape: [None, 32]\n",
      "Layer name: spiking_layer, layer type: HSpikingLayer, input shapes: [[None, 32]], output shape: [[None, 32]]\n",
      "Layer name: activation, layer type: Activation, input shapes: [[[None, 32]]], output shape: [[None, 32]]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[[None, 32]]], output shape: [10]\n",
      "Layer name: activation_1, layer type: Softmax, input shapes: [[10]], output shape: [10]\n",
      "Creating HLS model\n",
      "WARNING: You set a Part that does not correspond to the Board you specified. The correct Part is now set.\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "#config['InputShape'] = {'spiking_layer_input': (None, 784)}\n",
    "config['Model']['Precision'] = 'ap_fixed<12,6>'\n",
    "config['Model']['ReuseFactor'] = 1\n",
    "'''\n",
    "for Layer in config['LayerName'].keys():\n",
    "    config['LayerName'][Layer]['Strategy'] = 'Latency'\n",
    "    config['LayerName'][Layer]['ReuseFactor'] = 1\n",
    "    #config['LayerName'][Layer]['Precision'] = 'ap_fixed<8,4>'\n",
    "'''\n",
    "config['LayerName']['activation_1']['Strategy'] = 'Stable'\n",
    "'''\n",
    "for layer in ['conv1', 'conv2'] :\n",
    "    config['LayerName'][layer]['Precision'] = 'ap_fixed<8,4>'\n",
    "'''\n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "cfg = hls4ml.converters.create_config(backend='VivadoAccelerator')\n",
    "cfg['IOType'] = 'io_stream'\n",
    "cfg['HLSConfig'] = config\n",
    "cfg['KerasModel'] = model\n",
    "cfg['OutputDir'] = 'AlexNet_Alevo50'\n",
    "cfg['Board'] = 'alveo-u50'\n",
    "\n",
    "hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "\n",
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4223b376-e1f8-4244-b023-e7ca7222589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']\n",
    "os.environ['LD_PRELOAD'] = '/lib/x86_64-linux-gnu/libudev.so.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62182d24-d57c-4cad-84d9-596e36577e76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)\n",
      "  **** SW Build 2708876 on Wed Nov  6 21:39:14 MST 2019\n",
      "  **** IP Build 2700528 on Thu Nov  7 00:09:20 MST 2019\n",
      "    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.\n",
      "\n",
      "source /opt/Xilinx/Vivado/2019.2/scripts/vivado_hls/hls.tcl -notrace\n",
      "INFO: Applying HLS Y2K22 patch v1.2 for IP revision\n",
      "INFO: [HLS 200-10] Running '/opt/Xilinx/Vivado/2019.2/bin/unwrapped/lnx64.o/vivado_hls'\n",
      "INFO: [HLS 200-10] For user 'jovyan' on host '6307b0c947c6' (Linux_x86_64 version 4.15.0-212-generic) on Sat Jul 08 15:04:23 UTC 2023\n",
      "INFO: [HLS 200-10] In directory '/home/jovyan/Internship_Waseda/hls4ml/SNN/AlexNet_Alevo50'\n",
      "Sourcing Tcl script 'build_prj.tcl'\n",
      "INFO: [HLS 200-10] Opening project '/home/jovyan/Internship_Waseda/hls4ml/SNN/AlexNet_Alevo50/myproject_prj'.\n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject_axi.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'myproject_test.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'firmware/weights' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'tb_data' to the project\n",
      "INFO: [HLS 200-10] Opening solution '/home/jovyan/Internship_Waseda/hls4ml/SNN/AlexNet_Alevo50/myproject_prj/solution1'.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with a period of 5ns.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with an uncertainty of 0.625ns.\n",
      "INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 80.\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 80.\n",
      "***** C/RTL SYNTHESIS *****\n",
      "INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject.cpp' ... \n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:35:67\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:35:71\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:45:67\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:45:71\n",
      "WARNING: [HLS 200-471] Dataflow form checks found 4 issue(s) in file firmware/myproject.cpp\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject_axi.cpp' ... \n",
      "WARNING: [HLS 214-114] Since the only kind of statements allowed in a canonical dataflow region are variable declarations and function calls, the compiler may not be able to correctly handle the region: firmware/myproject_axi.cpp:17:2\n",
      "WARNING: [HLS 214-114] Since the only kind of statements allowed in a canonical dataflow region are variable declarations and function calls, the compiler may not be able to correctly handle the region: firmware/myproject_axi.cpp:29:5\n",
      "WARNING: [HLS 200-471] Dataflow form checks found 2 issue(s) in file firmware/myproject_axi.cpp\n",
      "INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:48 ; elapsed = 00:00:49 . Memory (MB): peak = 931.234 ; gain = 526.973 ; free physical = 32397 ; free virtual = 52530\n",
      "INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:48 ; elapsed = 00:00:49 . Memory (MB): peak = 931.234 ; gain = 526.973 ; free physical = 32397 ; free virtual = 52530\n",
      "INFO: [HLS 200-10] Starting code transformations ...\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 784u>::operator[]' into 'myproject_axi' (firmware/myproject_axi.cpp:21).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 784u>::operator[]' into 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 784u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config2>' (firmware/nnet_utils/nnet_dense_stream.h:44).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' (firmware/nnet_utils/nnet_dense_latency.h:42).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' (firmware/nnet_utils/nnet_dense_latency.h:42).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' into 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' (firmware/nnet_utils/nnet_dense_stream.h:19).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' into 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' (firmware/nnet_utils/nnet_dense_latency.h:66->firmware/nnet_utils/nnet_dense_stream.h:19).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>::operator[]' into 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, config6>' (firmware/nnet_utils/nnet_dense_stream.h:44).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, relu_config5>' (firmware/nnet_utils/nnet_activation_stream.h:54).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, relu_config5>' (firmware/nnet_utils/nnet_activation_stream.h:52).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, relu_config5>' (firmware/nnet_utils/nnet_activation_stream.h:52).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, relu_config5>' (firmware/nnet_utils/nnet_activation_stream.h:51).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>::operator[]' into 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 784u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config2>' (firmware/nnet_utils/nnet_dense_stream.h:60).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' into 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' (firmware/nnet_utils/nnet_dense_stream.h:19).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' into 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' (firmware/nnet_utils/nnet_dense_latency.h:66->firmware/nnet_utils/nnet_dense_stream.h:19).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>::operator[]' into 'myproject_axi' (firmware/myproject_axi.cpp:33).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>::operator[]' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config8>' (firmware/nnet_utils/nnet_activation_stream.h:244).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>::operator[]' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config8>' (firmware/nnet_utils/nnet_activation_stream.h:203).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>::operator[]' into 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, config6>' (firmware/nnet_utils/nnet_dense_stream.h:60).\n",
      "INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:01:17 ; elapsed = 00:01:18 . Memory (MB): peak = 947.238 ; gain = 542.977 ; free physical = 32247 ; free virtual = 52379\n",
      "INFO: [HLS 200-10] Checking synthesizability ...\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:43) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 8, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 8, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 8, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 8, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 10, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 10, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config8>' (firmware/nnet_utils/nnet_activation_stream.h:209) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, softmax_config8>' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config8>' (firmware/nnet_utils/nnet_activation_stream.h:224) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 10, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config8>' (firmware/nnet_utils/nnet_activation_stream.h:232) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, softmax_config8>' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config8>' (firmware/nnet_utils/nnet_activation_stream.h:235) automatically.\n",
      "WARNING: [SYNCHK 200-23] firmware/myproject_axi.cpp:33: variable-indexed range selection may cause suboptimal QoR.\n",
      "INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).\n",
      "INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:01:23 ; elapsed = 00:01:25 . Memory (MB): peak = 948.711 ; gain = 544.449 ; free physical = 32239 ; free virtual = 52371\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' on argument 'res.V.data.V' . This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' on argument 'res.V.data.V' . This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' on argument 'data_stream.V.data.V' . This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' (firmware/myproject.cpp:12:1) on argument 'dense_input.V.data.V' (firmware/myproject.cpp:7). This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' (firmware/myproject.cpp:12:98) on argument 'layer8_out.V.data.V' (firmware/myproject.cpp:8). This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-1103] Ignored data pack directive on non-struct variable 'out.data' (firmware/myproject_axi.cpp:3).\n",
      "WARNING: [XFORM 203-1103] Ignored data pack directive on non-struct variable 'in.data' (firmware/myproject_axi.cpp:3).\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_pack.data.V' (firmware/nnet_utils/nnet_activation_stream.h:237) into a 160-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:45) into a 512-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_dense_stream.h:55) into a 512-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_dense_stream.h:55) into a 160-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'ctype.data.V' (firmware/myproject_axi.cpp:18) into a 12544-bit variable.\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config8>' (firmware/nnet_utils/nnet_activation_stream.h:193:47).\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, relu_config5>' (firmware/nnet_utils/nnet_activation_stream.h:41:42).\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'DataPrepare' (firmware/nnet_utils/nnet_dense_stream.h:36) in function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, config6>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (firmware/myproject_axi.cpp:17) in function 'myproject_axi' automatically.\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' (firmware/nnet_utils/nnet_dense_latency.h:17:48).\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' (firmware/nnet_utils/nnet_dense_latency.h:17:48).\n",
      "INFO: [HLS 200-489] Unrolling loop 'SoftmaxArrayPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:201) in function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config8>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-2' (firmware/nnet_utils/nnet_activation_stream.h:213) in function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config8>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-3' (firmware/nnet_utils/nnet_activation_stream.h:222) in function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config8>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'SoftmaxInvPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:241) in function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config8>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ReLUPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:49) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, relu_config5>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'DataPack' (firmware/nnet_utils/nnet_dense_stream.h:42) in function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 784u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config2>' completely with a factor of 784.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ResPack' (firmware/nnet_utils/nnet_dense_stream.h:58) in function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 784u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config2>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'DataPack' (firmware/nnet_utils/nnet_dense_stream.h:42) in function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, config6>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ResPack' (firmware/nnet_utils/nnet_dense_stream.h:58) in function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, config6>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/myproject_axi.cpp:17) in function 'myproject_axi' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:37) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 128.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Product2' (firmware/nnet_utils/nnet_dense_latency.h:40) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ResetAccum' (firmware/nnet_utils/nnet_dense_latency.h:48) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Accum1' (firmware/nnet_utils/nnet_dense_latency.h:54) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 128.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Accum2' (firmware/nnet_utils/nnet_dense_latency.h:56) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_latency.h:64) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:37) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 784.\n",
      "ERROR: [XFORM 203-504] Stop unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:37) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' because it may cause large runtime and excessive memory usage due to increase in code size. Please avoid unrolling the loop or form sub-functions for code in the loop body.\n",
      "ERROR: [HLS 200-70] Pre-synthesis failed.\n",
      "command 'ap_source' returned error code\n",
      "    while executing\n",
      "\"source build_prj.tcl\"\n",
      "    (\"uplevel\" body line 1)\n",
      "    invoked from within\n",
      "\"uplevel \\#0 [list source $arg] \"\n",
      "\n",
      "INFO: [Common 17-206] Exiting vivado_hls at Sat Jul  8 15:06:25 2023...\n",
      "CSynthesis report not found.\n",
      "Vivado synthesis report not found.\n",
      "Cosim report not found.\n",
      "Timing report not found.\n",
      "\n",
      "****** Vivado v2019.2 (64-bit)\n",
      "  **** SW Build 2708876 on Wed Nov  6 21:39:14 MST 2019\n",
      "  **** IP Build 2700528 on Thu Nov  7 00:09:20 MST 2019\n",
      "    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.\n",
      "\n",
      "source design.tcl\n",
      "# set tcldir [file dirname [info script]]\n",
      "# source [file join $tcldir project.tcl]\n",
      "## variable project_name\n",
      "## set project_name \"myproject\"\n",
      "## variable backend\n",
      "## set backend \"vivadoaccelerator\"\n",
      "## variable part\n",
      "## set part \"xc7z020clg400-1\"\n",
      "## variable clock_period\n",
      "## set clock_period 5\n",
      "## variable clock_uncertainty\n",
      "## set clock_uncertainty 12.5%\n",
      "## set bit_width_hls_output 32\n",
      "## set bit_width_hls_input 32\n",
      "# create_project project_1 ${project_name}_vivado_accelerator -part xc7z020clg400-1 -force\n",
      "# set_property board_part tul.com.tw:pynq-z2:part0:1.0 [current_project]\n",
      "# set_property  ip_repo_paths  ${project_name}_prj [current_project]\n",
      "# update_ip_catalog\n",
      "INFO: [IP_Flow 19-234] Refreshing IP repositories\n",
      "INFO: [IP_Flow 19-1700] Loaded user IP repository '/home/jovyan/Internship_Waseda/hls4ml/SNN/AlexNet_Alevo50/myproject_prj'.\n",
      "INFO: [IP_Flow 19-2313] Loaded Vivado IP repository '/opt/Xilinx/Vivado/2019.2/data/ip'.\n",
      "# create_bd_design \"design_1\"\n",
      "Wrote  : </home/jovyan/Internship_Waseda/hls4ml/SNN/AlexNet_Alevo50/myproject_vivado_accelerator/project_1.srcs/sources_1/bd/design_1/design_1.bd> \n",
      "# startgroup\n",
      "# create_bd_cell -type ip -vlnv xilinx.com:ip:processing_system7:5.5 processing_system7_0\n",
      "WARNING: [BD 41-176] The physical port 'S_AXI_GP2_rd_socket' specified in the portmap, is not found on the block! \n",
      "WARNING: [BD 41-176] The physical port 'S_AXI_GP2_wr_socket' specified in the portmap, is not found on the block! \n",
      "WARNING: [BD 41-176] The physical port 'S_AXI_GP3_rd_socket' specified in the portmap, is not found on the block! \n",
      "WARNING: [BD 41-176] The physical port 'S_AXI_GP3_wr_socket' specified in the portmap, is not found on the block! \n",
      "# endgroup\n",
      "# apply_bd_automation -rule xilinx.com:bd_rule:processing_system7 -config {make_external \"FIXED_IO, DDR\" apply_board_preset \"1\" Master \"Disable\" Slave \"Disable\" }  [get_bd_cells processing_system7_0]\n",
      "# startgroup\n",
      "# set_property -dict [list CONFIG.PCW_USE_S_AXI_HP0 {1}] [get_bd_cells processing_system7_0]\n",
      "CRITICAL WARNING: [PSU-1]  Parameter : PCW_UIPARAM_DDR_DQS_TO_CLK_DELAY_0 has negative value -0.051 . PS DDR interfaces might fail when entering negative DQS skew values. \n",
      "CRITICAL WARNING: [PSU-2]  Parameter : PCW_UIPARAM_DDR_DQS_TO_CLK_DELAY_1 has negative value -0.006 . PS DDR interfaces might fail when entering negative DQS skew values. \n",
      "CRITICAL WARNING: [PSU-3]  Parameter : PCW_UIPARAM_DDR_DQS_TO_CLK_DELAY_2 has negative value -0.009 . PS DDR interfaces might fail when entering negative DQS skew values. \n",
      "CRITICAL WARNING: [PSU-4]  Parameter : PCW_UIPARAM_DDR_DQS_TO_CLK_DELAY_3 has negative value -0.033 . PS DDR interfaces might fail when entering negative DQS skew values. \n",
      "WARNING: [BD 41-176] The physical port 'S_AXI_GP2_rd_socket' specified in the portmap, is not found on the block! \n",
      "WARNING: [BD 41-176] The physical port 'S_AXI_GP2_wr_socket' specified in the portmap, is not found on the block! \n",
      "WARNING: [BD 41-176] The physical port 'S_AXI_GP3_rd_socket' specified in the portmap, is not found on the block! \n",
      "WARNING: [BD 41-176] The physical port 'S_AXI_GP3_wr_socket' specified in the portmap, is not found on the block! \n",
      "# endgroup\n",
      "# startgroup\n",
      "# create_bd_cell -type ip -vlnv xilinx.com:ip:axi_dma:7.1 axi_dma_0\n",
      "# endgroup\n",
      "# set_property -dict [list CONFIG.c_s_axis_s2mm_tdata_width.VALUE_SRC USER] [get_bd_cells axi_dma_0]\n",
      "# set_property -dict [list CONFIG.c_include_sg {0} CONFIG.c_sg_length_width {26} CONFIG.c_sg_include_stscntrl_strm {0} CONFIG.c_m_axi_mm2s_data_width ${bit_width_hls_input} CONFIG.c_m_axis_mm2s_tdata_width ${bit_width_hls_input} CONFIG.c_mm2s_burst_size {256} CONFIG.c_s_axis_s2mm_tdata_width ${bit_width_hls_output} CONFIG.c_s_axis_s2mm_data_width ${bit_width_hls_output} CONFIG.c_s2mm_burst_size {256}] [get_bd_cells axi_dma_0]\n",
      "CRITICAL WARNING: [BD 41-1276] Cannot set the parameter c_s_axis_s2mm_data_width on /axi_dma_0. Parameter does not exist\n",
      "# startgroup\n",
      "# apply_bd_automation -rule xilinx.com:bd_rule:axi4 -config { Clk_master {Auto} Clk_slave {Auto} Clk_xbar {Auto} Master {/processing_system7_0/M_AXI_GP0} Slave {/axi_dma_0/S_AXI_LITE} ddr_seg {Auto} intc_ip {New AXI Interconnect} master_apm {0}}  [get_bd_intf_pins axi_dma_0/S_AXI_LITE]\n",
      "INFO: [Ipptcl 7-1463] No Compatible Board Interface found. Board Tab not created in customize GUI\n",
      "Slave segment </axi_dma_0/S_AXI_LITE/Reg> is being mapped into address space </processing_system7_0/Data> at <0x4040_0000 [ 64K ]>\n",
      "# apply_bd_automation -rule xilinx.com:bd_rule:axi4 -config { Clk_master {Auto} Clk_slave {Auto} Clk_xbar {Auto} Master {/axi_dma_0/M_AXI_MM2S} Slave {/processing_system7_0/S_AXI_HP0} ddr_seg {Auto} intc_ip {New AXI Interconnect} master_apm {0}}  [get_bd_intf_pins processing_system7_0/S_AXI_HP0]\n",
      "Slave segment </processing_system7_0/S_AXI_HP0/HP0_DDR_LOWOCM> is being mapped into address space </axi_dma_0/Data_MM2S> at <0x0000_0000 [ 512M ]>\n",
      "# endgroup\n",
      "# apply_bd_automation -rule xilinx.com:bd_rule:axi4 -config { Clk_master {Auto} Clk_slave {/processing_system7_0/FCLK_CLK0 (100 MHz)} Clk_xbar {/processing_system7_0/FCLK_CLK0 (100 MHz)} Master {/axi_dma_0/M_AXI_S2MM} Slave {/processing_system7_0/S_AXI_HP0} ddr_seg {Auto} intc_ip {/axi_mem_intercon} master_apm {0}}  [get_bd_intf_pins axi_dma_0/M_AXI_S2MM]\n",
      "Slave segment </processing_system7_0/S_AXI_HP0/HP0_DDR_LOWOCM> is being mapped into address space </axi_dma_0/Data_S2MM> at <0x0000_0000 [ 512M ]>\n",
      "# startgroup\n",
      "# create_bd_cell -type ip -vlnv xilinx.com:hls:${project_name}_axi:1.0 ${project_name}_axi_0\n",
      "ERROR: [Common 17-39] 'create_bd_cell' failed due to earlier errors.\n",
      "\n",
      "    while executing\n",
      "\"create_bd_cell -type ip -vlnv xilinx.com:hls:${project_name}_axi:1.0 ${project_name}_axi_0\"\n",
      "    (file \"design.tcl\" line 39)\n",
      "INFO: [Common 17-17] undo 'startgroup'\n",
      "INFO: [Common 17-206] Exiting Vivado at Sat Jul  8 15:06:42 2023...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [BD 5-390] IP definition not found for VLNV: xilinx.com:hls:myproject_axi:1.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSynthesis report not found.\n",
      "Vivado synthesis report not found.\n",
      "Cosim report not found.\n",
      "Timing report not found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_model.build(csim=False, export=True, bitfile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f4d01-5f07-46d9-9174-c9ff923340a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

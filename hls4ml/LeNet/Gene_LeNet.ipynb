{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 04:53:14.541317: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "import os\n",
    "\n",
    "os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']\n",
    "os.environ['LD_PRELOAD'] = '/lib/x86_64-linux-gnu/libudev.so.1'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the jet tagging dataset from Open ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "#x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "np.save('X_test.npy', x_test)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from callbacks import all_callbacks\n",
    "from tensorflow.keras.layers import Activation\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras import QConv2D\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "from tensorflow.keras.layers import Flatten, MaxPooling2D, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 04:53:17.310786: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer LecunUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (QConv2D)             (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " relu1 (QActivation)         (None, 24, 24, 16)        0         \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 12, 12, 16)        0         \n",
      "                                                                 \n",
      " conv2 (QConv2D)             (None, 8, 8, 4)           1604      \n",
      "                                                                 \n",
      " relu2 (QActivation)         (None, 8, 8, 4)           0         \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 4, 4, 4)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (QDense)                (None, 30)                1950      \n",
      "                                                                 \n",
      " fc2 (QDense)                (None, 10)                310       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,280\n",
      "Trainable params: 4,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    Input(shape=(28, 28, 1))\n",
    ")\n",
    "\n",
    "# Conv 1\n",
    "model.add(\n",
    "    QConv2D(\n",
    "        16,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(1, 1),\n",
    "        padding='valid',\n",
    "        name='conv1',\n",
    "        kernel_quantizer=quantized_bits(8, 4, alpha=1),\n",
    "        bias_quantizer=quantized_bits(8, 4, alpha=1),\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=l1(0.0001)\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    QActivation(activation=quantized_relu(4), name='relu1')\n",
    ")\n",
    "model.add(\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid', name='pool1')\n",
    ")\n",
    "\n",
    "# Conv 2\n",
    "model.add(\n",
    "    QConv2D(\n",
    "        4,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(1, 1),\n",
    "        padding='valid',\n",
    "        name='conv2',\n",
    "        kernel_quantizer=quantized_bits(8, 4, alpha=1),\n",
    "        bias_quantizer=quantized_bits(8, 4, alpha=1),\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=l1(0.0001)\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    QActivation(activation=quantized_relu(4), name='relu2')\n",
    ")\n",
    "model.add(\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid', name='pool2')\n",
    ")\n",
    "\n",
    "# Flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "# FC 1\n",
    "model.add(\n",
    "    QDense(\n",
    "        30,\n",
    "        name='fc1',\n",
    "        kernel_quantizer=quantized_bits(8, 4, alpha=1),\n",
    "        bias_quantizer=quantized_bits(8, 4, alpha=1),\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=l1(0.0001)\n",
    "    )\n",
    ")\n",
    "\n",
    "# FC 2\n",
    "model.add(\n",
    "    QDense(\n",
    "        10,\n",
    "        name='fc2',\n",
    "        kernel_quantizer=quantized_bits(8, 4, alpha=1),\n",
    "        bias_quantizer=quantized_bits(8, 4, alpha=1),\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=l1(0.0001)\n",
    "    )\n",
    ")\n",
    "\n",
    "model.add(Activation(activation='softmax', name='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "\n",
    "pruning_params = {\"pruning_schedule\": pruning_schedule.ConstantSparsity(0.75, begin_step=2000, frequency=100)}\n",
    "model = prune.prune_low_magnitude(model, **pruning_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "59/59 [==============================] - 10s 133ms/step - loss: 1.8842 - accuracy: 0.4683 - val_loss: 1.3148 - val_accuracy: 0.7336\n",
      "Epoch 2/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.9913 - accuracy: 0.8062 - val_loss: 0.6981 - val_accuracy: 0.8717\n",
      "Epoch 3/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.5595 - accuracy: 0.8834 - val_loss: 0.4186 - val_accuracy: 0.9162\n",
      "Epoch 4/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.3850 - accuracy: 0.9176 - val_loss: 0.3241 - val_accuracy: 0.9304\n",
      "Epoch 5/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.3153 - accuracy: 0.9303 - val_loss: 0.2693 - val_accuracy: 0.9440\n",
      "Epoch 6/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.2687 - accuracy: 0.9422 - val_loss: 0.2399 - val_accuracy: 0.9496\n",
      "Epoch 7/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.2480 - accuracy: 0.9467 - val_loss: 0.2206 - val_accuracy: 0.9553\n",
      "Epoch 8/30\n",
      "59/59 [==============================] - 7s 126ms/step - loss: 0.2269 - accuracy: 0.9523 - val_loss: 0.2033 - val_accuracy: 0.9605\n",
      "Epoch 9/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.2174 - accuracy: 0.9541 - val_loss: 0.1957 - val_accuracy: 0.9613\n",
      "Epoch 10/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.2038 - accuracy: 0.9584 - val_loss: 0.1838 - val_accuracy: 0.9633\n",
      "Epoch 11/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.1945 - accuracy: 0.9610 - val_loss: 0.1755 - val_accuracy: 0.9658\n",
      "Epoch 12/30\n",
      "59/59 [==============================] - 7s 126ms/step - loss: 0.1891 - accuracy: 0.9628 - val_loss: 0.1674 - val_accuracy: 0.9682\n",
      "Epoch 13/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.1836 - accuracy: 0.9639 - val_loss: 0.1665 - val_accuracy: 0.9687\n",
      "Epoch 14/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.1790 - accuracy: 0.9653 - val_loss: 0.1608 - val_accuracy: 0.9691\n",
      "Epoch 15/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.1717 - accuracy: 0.9664 - val_loss: 0.1558 - val_accuracy: 0.9714\n",
      "Epoch 16/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.1744 - accuracy: 0.9661 - val_loss: 0.1557 - val_accuracy: 0.9697\n",
      "Epoch 17/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.1647 - accuracy: 0.9686 - val_loss: 0.1504 - val_accuracy: 0.9730\n",
      "Epoch 18/30\n",
      "59/59 [==============================] - 7s 126ms/step - loss: 0.1650 - accuracy: 0.9684 - val_loss: 0.1504 - val_accuracy: 0.9716\n",
      "Epoch 19/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.1581 - accuracy: 0.9703 - val_loss: 0.1496 - val_accuracy: 0.9727\n",
      "Epoch 20/30\n",
      "59/59 [==============================] - 7s 126ms/step - loss: 0.1543 - accuracy: 0.9720 - val_loss: 0.1496 - val_accuracy: 0.9738\n",
      "Epoch 21/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.1537 - accuracy: 0.9718 - val_loss: 0.1423 - val_accuracy: 0.9734\n",
      "Epoch 22/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.1476 - accuracy: 0.9737 - val_loss: 0.1452 - val_accuracy: 0.9745\n",
      "Epoch 23/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.1485 - accuracy: 0.9732 - val_loss: 0.1380 - val_accuracy: 0.9760\n",
      "Epoch 24/30\n",
      "59/59 [==============================] - 7s 126ms/step - loss: 0.1484 - accuracy: 0.9731 - val_loss: 0.1344 - val_accuracy: 0.9765\n",
      "Epoch 25/30\n",
      "59/59 [==============================] - 7s 126ms/step - loss: 0.1462 - accuracy: 0.9735 - val_loss: 0.1324 - val_accuracy: 0.9779\n",
      "Epoch 26/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.1431 - accuracy: 0.9741 - val_loss: 0.1341 - val_accuracy: 0.9757\n",
      "Epoch 27/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.1440 - accuracy: 0.9740 - val_loss: 0.1525 - val_accuracy: 0.9719\n",
      "Epoch 28/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.1392 - accuracy: 0.9751 - val_loss: 0.1310 - val_accuracy: 0.9765\n",
      "Epoch 29/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.1430 - accuracy: 0.9744 - val_loss: 0.1279 - val_accuracy: 0.9788\n",
      "Epoch 30/30\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.1380 - accuracy: 0.9761 - val_loss: 0.1302 - val_accuracy: 0.9777\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "train = True\n",
    "if train:\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(\n",
    "        optimizer=adam, \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=1024,\n",
    "        epochs=30,\n",
    "        validation_data=(x_test, y_test),\n",
    "        shuffle=True,\n",
    "    )\n",
    "    model = strip_pruning(model)\n",
    "    model.save('LeNet_Prune_Model.h5')\n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "    from qkeras.utils import _add_supported_quantized_objects\n",
    "\n",
    "    co = {}\n",
    "    _add_supported_quantized_objects(co)\n",
    "    model = load_model('model_3/KERAS_check_best_model.h5', custom_objects=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11 (main, Apr 20 2023, 13:58:42) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "606c0b78d9e04732b14ee9e45c5bfff9d12dee0e0feabd86b8db33116293c133"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

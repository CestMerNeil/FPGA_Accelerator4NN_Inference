{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 15:18:59.707850: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-04 15:19:01.471553: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "/home/lab-shi/anaconda3/envs/hls4ml/lib/python3.8/site-packages/keras/initializers/initializers.py:120: UserWarning: The initializer LecunUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "import tensorflow as tf\n",
    "\n",
    "co = {}\n",
    "_add_supported_quantized_objects(co)\n",
    "import os\n",
    "\n",
    "model = load_model('LeNet_Prune_Model.h5', custom_objects=co)\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (QConv2D)             (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " relu1 (QActivation)         (None, 24, 24, 16)        0         \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 12, 12, 16)        0         \n",
      "                                                                 \n",
      " conv2 (QConv2D)             (None, 8, 8, 4)           1604      \n",
      "                                                                 \n",
      " relu2 (QActivation)         (None, 8, 8, 4)           0         \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 4, 4, 4)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (QDense)                (None, 30)                1950      \n",
      "                                                                 \n",
      " fc2 (QDense)                (None, 10)                310       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,280\n",
      "Trainable params: 4,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n",
      "(10000, 1, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(x_test.shape)\n",
    "\n",
    "x_test = np.expand_dims(x_test, axis=1)\n",
    "\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 15ms/step\n",
      "Classified 10000 samples in  4.92759370803833 seconds. ( 2029.3880933582468 inferences per second)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "len_data = len(x_test)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "inf_time = end_time - start_time\n",
    "\n",
    "inf_per_sec = len_data / inf_time\n",
    "\n",
    "print(\"Classified\", len_data, \"samples in \", inf_time, \"seconds. (\", inf_per_sec, \"inferences per second)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "606c0b78d9e04732b14ee9e45c5bfff9d12dee0e0feabd86b8db33116293c133"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
